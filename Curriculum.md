# 커리큘럼

<aside>
💡 해당 커리큘럼은 가이드라인입니다. 반드시 이 커리큘럼을 따라야하지 않습니다. 팀 별로 협의하에 새로운 커리큘럼으로 진행해주셔도 됩니다. 또한 새로운 커리큘럼으로 진행하시는 경우, 팀 별 노션 페이지에 커리큘럼을 정리해주세요. 서로 참고하며 발전하는 스터디를 지향합니다 😊
아래 커리큘럼에 잘못된 점이나 발전할 점이 보이는 경우, 해당하는 부분에 댓글을 달아주세요!

</aside>

# ver 1

### **1주차: 프로젝트 오리엔테이션 및 환경 설정**

- **목표**: 전체 프로젝트 개요를 파악하고, 로컬 개발 환경을 설정하여 실습에 필요한 기반을 마련합니다.
- **조사할 키워드**:
    - **VirtualBox**
    - **Vagrant**
    - **Docker**
    - **Minikube**
    - **Git**
- **실습 내용**:
    1. **프로젝트 개요**:
        - 프로젝트의 목표와 주요 기술 스택(Hadoop, Spark, Flask, Docker 등) 소개.
        - 로컬 환경에서 가상 머신(VM)을 사용한 분산 시스템 구축의 필요성과 이점 설명.
    2. **가상 환경 설정**:
        - **VirtualBox 및 Vagrant 설치**: 로컬에서 여러 개의 가상 머신을 쉽게 관리하기 위해 VirtualBox와 Vagrant를 설치.
        - **가상 머신 생성**: Vagrant를 사용해 Ubuntu 기반의 가상 머신 3~5개 생성 및 네트워크 구성.
    3. **필수 개발 도구 설치**:
        - 각 가상 머신에 **Docker**, **Python**, **Git** 등 필수 개발 도구 설치.
        - 프로젝트의 버전 관리를 위해 Git 리포지토리 초기화 및 연결.
    4. **프로젝트 관리 도구 설정**:
        - 협업 도구(예: Trello, Jira 등) 설정 및 사용법 소개.
        - 프로젝트 진행 및 관리 계획 수립.

### **2주차: 영화 데이터셋 수집 및 초기 분석**

- **목표**: 영화 데이터셋을 수집하여 초기 데이터를 분석하고, 프로젝트에 사용할 데이터를 준비합니다.
- **조사할 키워드**:
    - **MovieLens Dataset**
    - **HDFS (Hadoop Distributed File System)**
    - **Data Preprocessing Techniques**
    - **CSV, JSON Data Formats**
- **실습 내용**:
    1. **데이터 수집**:
        - MovieLens와 같은 공개된 영화 데이터셋을 선택하여 다운로드.
        - 데이터셋의 구조(사용자 정보, 영화 정보, 평점 등)를 분석하고, 적절한 형식으로 변환.
    2. **HDFS에 데이터 저장**:
        - 각 VM에 Hadoop을 설치하고, HDFS를 설정.
        - 수집된 영화 데이터셋을 HDFS에 저장하고, 데이터 복제 및 분산 저장 설정.
    3. **데이터 탐색 및 전처리**:
        - 데이터를 탐색하여 결측치, 중복 데이터 등 문제점 파악.
        - 기본적인 데이터 전처리(결측치 처리, 형식 변환 등)를 수행하여 데이터의 품질을 향상.
        - 전처리된 데이터를 다시 HDFS에 저장하여 다음 단계를 위한 준비 완료.

### **3주차: Hadoop 클러스터 구축 및 데이터 저장**

- **목표**: Hadoop과 HDFS를 로컬 환경에 설치하고, 클러스터를 구성하여 데이터 저장을 위한 인프라를 구축합니다.
- **조사할 키워드**:
    - **Hadoop Installation**
    - **HDFS Configuration**
    - **Namenode and Datanode Setup**
    - **Hadoop Cluster Setup on Local VMs**
- **실습 내용**:
    1. **Hadoop 설치**:
        - 각 가상 머신에 Hadoop 설치 및 환경 변수 설정.
        - 기본적인 Hadoop 디렉터리 구조와 설정 파일(hdfs-site.xml, core-site.xml) 이해 및 수정.
    2. **HDFS 클러스터 구성**:
        - HDFS 클러스터를 구축하여 다수의 가상 머신이 분산 파일 시스템을 공유할 수 있도록 설정.
        - Namenode와 Datanode를 설정하여 클러스터를 구성.
    3. **데이터 저장**:
        - 영화 데이터셋을 HDFS에 업로드하고, 데이터 복제 메커니즘 확인.
        - HDFS 명령어(hdfs dfs -put, -get 등)를 사용한 파일 관리 실습.

### **4주차: Flask 기반 웹 서비스 초기 구축**

- **목표**: Flask를 사용하여 웹 애플리케이션의 기본 구조를 설계하고, RESTful API의 초기 엔드포인트를 구현합니다.
- **조사할 키워드**:
    - **Flask Installation**
    - **RESTful API Design**
    - **Flask Routing**
    - **JSON Data Format**
- **실습 내용**:
    1. **Flask 설치 및 초기 설정**:
        - 각 가상 머신에서 Flask 설치 및 기본 애플리케이션 구조 생성.
        - 프로젝트 구조 정의(app, routes, models 등).
    2. **RESTful API 설계**:
        - 기본 API 엔드포인트(예: 영화 목록 조회, 사용자 등록)를 설계.
        - API 요청 및 응답 구조 정의(JSON 사용).
    3. **기본 API 구현**:
        - 간단한 API 엔드포인트를 구현하여 영화 데이터를 조회할 수 있는 기능 제공.
        - 로컬 서버를 실행하고 Postman 등을 사용해 API 테스트.

### **5주차: MapReduce를 이용한 데이터 전처리**

- **목표**: 대규모 데이터셋의 전처리를 위해 MapReduce 작업을 수행하고, 전처리된 데이터를 저장합니다.
- **조사할 키워드**:
    - **MapReduce Concepts**
    - **Map and Reduce Phases**
    - **Hadoop Streaming**
    - **Job Configuration in Hadoop**
- **실습 내용**:
    1. **MapReduce 개념 이해**:
        - MapReduce의 개념과 동작 원리(Map 단계, Reduce 단계) 학습.
        - 간단한 MapReduce 프로그램의 구조 이해.
    2. **MapReduce 작업 수행**:
        - 영화 데이터셋을 대상으로 한 MapReduce 작업을 설계(예: 특정 연도의 영화별 평점 평균 계산).
        - 작업 결과를 HDFS에 저장하고, 데이터 전처리 결과 확인.
    3. **결과 분석 및 저장**:
        - 전처리된 데이터를 분석하여 다음 단계의 데이터 모델링 및 분석 준비.
        - 전처리된 데이터가 Flask 애플리케이션과 연동될 수 있도록 데이터 형식 조정.

### **6주차: Flask와 데이터베이스 연동**

- **목표**: Flask 애플리케이션과 데이터베이스를 연동하여 데이터의 CRUD 기능을 구현합니다.
- **조사할 키워드**:
    - **SQLAlchemy ORM**
    - **Relational Database Concepts**
    - **CRUD Operations**
    - **Database Migrations**
- **실습 내용**:
    1. **SQLAlchemy 설치 및 설정**:
        - SQLAlchemy 설치 및 Flask와의 연동 설정.
        - 데이터베이스 연결을 위한 초기 설정(DB URI 설정 등).
    2. **데이터베이스 모델링**:
        - 영화와 관련된 데이터 모델(예: Movie, User, Rating) 설계.
        - 모델을 바탕으로 데이터베이스 테이블 생성.
    3. **CRUD 기능 구현**:
        - 영화 데이터에 대한 CRUD(Create, Read, Update, Delete) API 엔드포인트 구현.
        - 데이터베이스에 저장된 데이터를 읽고, 새로운 데이터를 추가하는 API 기능 테스트.

### **7주차: 추천 알고리즘 설계 및 Spark 클러스터 구축**

- **목표**: 영화 추천 알고리즘을 Spark MLlib을 활용해 설계하고, Spark 클러스터를 로컬 환경에 구축하여 대규모 데이터 처리 환경을 마련합니다.
- **조사할 키워드**:
    - **Collaborative Filtering**
    - **Alternating Least Squares (ALS)**
    - **Spark Installation**
    - **Spark RDD and DataFrame**
- **실습 내용**:
    1. **추천 알고리즘 설계**:
        - 협업 필터링(Collaborative Filtering) 기반의 추천 알고리즘 개념 이해.
        - ALS 알고리즘을 사용한 추천 시스템 설계 및 데이터 준비.
    2. **Spark 설치 및 설정**:
        - 각 가상 머신에 Spark 설치 및 클러스터 구성.
        - Spark의 RDD(Resilient Distributed Dataset) 개념과 기본 명령어 학습.
    3. **데이터 처리 실습**:
        - Spark를 사용하여 영화 추천 모델을 학습하기 위한 데이터 전처리 및 분석 작업 수행.
        - MapReduce와 Spark의 성능 비교 실습.

### **8주차: Flask에서의 사용자 인증 및 권한 관리**

- **목표**: Flask 웹 서비스에 사용자 인증 및 권한 관리 기능을 추가하여 보안을 강화합니다.
- **조사할 키워드**:
    - **Flask-Security**
    - **JWT (JSON Web Tokens)**
    - **OAuth2**
    - **User Authentication and Authorization**
- **실습 내용**:
    1. **Flask-Security 또는 JWT 설정**:
        - Flask-Security 또는 Flask-JWT-Extended 설치 및 초기 설정.
        - 사용자 등록, 로그인, 로그아웃 기능 구현.
    2. **사용자 인증 및 권한 관리**:
        - JWT를 사용한 토큰 기반 인증 시스템 구현.
        - API 엔드포인트에 대한 접근 제어(권한 관리) 설정.
    3. **보안 테스트**:
        - 사용자 인증 및 권한 관리 기능 테스트.
        - 보안 설정이 잘 작동하는지 확인하고, 불필요한 접근이 차단되는지 검증.

### **9주차: Spark를 활용한 추천 시스템 모델 학습**

- **목표**: Spark MLlib을 사용하여 영화 추천 모델을 학습시키고, 성능을 평가합니다.
- **조사할 키워드**:
    - **Spark MLlib**
    - **Model Training and Evaluation**
    - **Root Mean Squared Error (RMSE)**
    - **Precision and Recall Metrics**
- **실습 내용**:
    1. **Spark MLlib 개념 학습**:
        - Spark MLlib의 주요 기능과 알고리즘 학습.
        - 협업 필터링 모델(ALS, Alternating Least Squares) 이해.
    2. **추천 모델 학습**:
        - Spark를 사용해 영화 데이터셋을 기반으로 추천 모델 학습.
        - 모델 학습 결과를 바탕으로 사용자별 맞춤형 추천 리스트 생성.
    3. **모델 성능 평가**:
        - 추천 모델의 성능을 평가하기 위한 메트릭(예: RMSE, Precision, Recall) 설정.
        - 모델 성능을 평가하고 결과를 저장.

### **10주차: Hive 설치 및 쿼리 작성**

- **목표**: Hive를 설치하고, SQL-like 쿼리로 데이터를 분석하여 프로젝트에 필요한 정보를 추출합니다.
- **조사할 키워드**:
    - **Apache Hive**
    - **HiveQL**
    - **Data Warehousing Concepts**
    - **Hive Metastore Configuration**
- **실습 내용**:
    1. **Hive 설치 및 설정**:
        - 각 가상 머신에 Hive 설치 및 설정(Hive Metastore 설정 포함).
        - HDFS와 Hive 연동 설정.
    2. **데이터 쿼리 작성**:
        - HiveQL을 사용해 HDFS에 저장된 영화 데이터셋에 대해 SQL-like 쿼리 작성.
        - 주요 분석 쿼리 작성(예: 특정 연도별 평균 평점 계산, 특정 장르의 인기 영화 리스트 추출).
    3. **결과 연동**:
        - Hive 쿼리 결과를 Flask 애플리케이션에 연동하여 사용자에게 제공.
        - Flask API에서 Hive 쿼리 결과를 조회할 수 있는 엔드포인트 추가.

### **11주차: Flask와 추천 시스템 통합**

- **목표**: 추천 시스템을 Flask API와 통합하여 웹 서비스에서 사용자 맞춤형 추천 기능을 제공합니다.
- **조사할 키워드**:
    - **RESTful API Integration**
    - **Microservices Architecture**
    - **API Gateway**
- **실습 내용**:
    1. **추천 시스템 API 설계**:
        - 사용자 맞춤형 영화 추천을 제공하기 위한 API 엔드포인트 설계.
        - API 요청 시 Spark에서 학습된 추천 모델을 사용하여 실시간으로 추천 리스트 생성.
    2. **API 구현 및 테스트**:
        - 추천 엔진을 Flask API와 통합하여 사용자 맞춤형 추천 기능 구현.
        - 로컬 환경에서 API를 테스트하고 성능 최적화.
    3. **사용자 인터페이스 개선**:
        - 추천 결과를 사용자에게 보여주기 위한 기본 UI 설계 및 구현(Flask 템플릿 사용 가능).
        - UI와 추천 시스템 간의 데이터 연동 및 사용자 경험 개선.

### **12주차: 시스템 최적화 및 테스트**

- **목표**: 전체 시스템의 성능을 최적화하고, 안정적인 운영을 위한 테스트를 수행합니다.
- **조사할 키워드**:
    - **Performance Tuning in Spark**
    - **Flask API Optimization**
    - **Load Testing Tools (e.g., JMeter)**
    - **Docker Resource Management**
- **실습 내용**:
    1. **Spark 최적화**:
        - Spark 작업의 성능 최적화를 위한 설정(메모리 관리, 병렬 처리 최적화 등) 수행.
        - RDD 캐싱, 파티셔닝 등의 기술을 사용해 성능 개선.
    2. **Flask API 성능 최적화**:
        - Flask 애플리케이션의 성능을 향상시키기 위한 최적화 기법 적용(예: 쿼리 최적화, 캐싱).
        - API 응답 시간을 줄이기 위한 최적화 작업.
    3. **시스템 통합 테스트**:
        - 전체 시스템(Hadoop, Spark, Flask)의 통합 테스트 수행.
        - 부하 테스트를 통해 시스템의 확장성 및 안정성을 검증.

### **13주차: 추가 기능 구현 및 개선**

- **목표**: 프로젝트의 요구사항에 따라 추가 기능을 구현하고, 기존 기능을 개선합니다.
- **조사할 키워드**:
    - **Real-time Data Processing**
    - **Data Visualization Tools (e.g., Grafana)**
    - **User Feedback Loops**
    - **Code Refactoring Techniques**
- **실습 내용**:
    1. **추가 기능 구현**:
        - 실시간 추천 기능, 사용자 평가 기능 등 추가 요구사항을 반영한 기능 구현.
        - 데이터 시각화 기능 추가(예: 추천 결과를 그래프 또는 차트로 표시).
    2. **기존 기능 개선**:
        - 사용자 피드백을 기반으로 기존 기능 개선(예: 추천 알고리즘 개선, UI 개선).
        - Flask API 및 데이터 처리 파이프라인 개선.
    3. **코드 리팩토링**:
        - 코드 품질 향상을 위해 코드 리팩토링 수행.
        - 코드 리뷰 및 개선 사항 반영.

### **14주차: 프로젝트 배포 준비**

- **목표**: 프로젝트의 배포 전략을 수립하고, 실제 운영 환경에 배포하기 위한 준비를 완료합니다.
- **조사할 키워드**:
    - **Docker Compose**
    - **Minikube (Kubernetes on Local)**
    - **CI/CD Best Practices**
    - **Staging and Production Environments**
- **실습 내용**:
    1. **Docker를 이용한 컨테이너화**:
        - Flask 애플리케이션, Hadoop, Spark 클러스터를 Docker 컨테이너로 구성.
        - Docker Compose를 사용해 전체 시스템을 하나의 환경에서 관리.
    2. **배포 스크립트 작성**:
        - 자동 배포를 위한 스크립트 작성(Bash, Ansible 등 활용 가능).
        - 배포 자동화를 위한 Git Hooks 또는 CI/CD 파이프라인 설정.
    3. **스테이징 환경 배포**:
        - 실제 운영 환경과 유사한 스테이징 환경을 구성하고 배포 테스트 수행.
        - 배포 과정에서 발생할 수 있는 문제를 사전에 해결.

### **15주차: CI/CD 시스템 구축 및 통합 테스트**

- **목표**: CI/CD 파이프라인 구축을 통해 코드의 변경 사항이 자동으로 테스트되고 배포될 수 있는 시스템을 완성합니다.
- **조사할 키워드**:
    - **Jenkins/GitLab CI/GitHub Actions**
    - **Pipeline as Code**
    - **Docker Deployment Automation**
    - **Continuous Integration and Continuous Deployment**
- **실습 내용**:
    1. **CI/CD 개념 이해**:
        - CI/CD의 개념과 중요성 학습.
        - Jenkins, GitLab CI, GitHub Actions 중 하나를 선택해 사용.
    2. **CI/CD 도구 설치 및 설정**:
        - 로컬 또는 클라우드 환경에서 Jenkins, GitLab CI, 또는 GitHub Actions 설정.
        - 프로젝트 코드 저장소(Git)를 CI/CD 도구와 연동.
    3. **파이프라인 설정**:
        - 빌드 파이프라인 구성: 코드가 푸시될 때 자동으로 빌드가 수행되도록 파이프라인 작성.
        - 자동 테스트 설정: 코드 변경 시 유닛 테스트 및 통합 테스트가 자동으로 실행되도록 설정.
    4. **자동 배포 설정**:
        - 배포 스크립트 작성: Docker를 활용하여 Flask 애플리케이션과 Spark, Hadoop 클러스터를 자동으로 배포하는 스크립트 작성.
        - 스테이징 환경 설정: 실제 운영 전에 테스트할 수 있는 스테이징 환경 구성 및 자동 배포.
    5. **통합 테스트**:
        - 전체 시스템 테스트: CI/CD 파이프라인을 통해 코드 변경이 테스트되고 스테이징 환경에 자동으로 배포되는지 확인.
        - 문제 해결: 통합 과정에서 발생하는 문제를 해결하고, 파이프라인을 안정화.

### **16주차: 최종 프로젝트 배포 및 발표**

- **목표**: CI/CD 시스템을 통해 최종 프로젝트를 운영 환경에 배포하고, 프로젝트 발표를 통해 학습을 마무리합니다.
- **조사할 키워드**:
    - **Monitoring Tools (e.g., Prometheus, Grafana)**
    - **Final Presentation Techniques**
    - **Deployment Rollbacks**
    - **Post-mortem Analysis**
- **실습 내용**:
    1. **최종 배포 준비**:
        - 최종 배포 환경 설정: 실제 운영 환경에 맞춰 최종 배포 설정을 완료.
        - 배포 테스트: 운영 환경에 배포하기 전에 스테이징 환경에서 최종 배포 테스트를 수행.
    2. **운영 환경 배포**:
        - CI/CD 파이프라인 사용: CI/CD 시스템을 통해 최종 프로젝트를 운영 환경에 자동 배포.
        - 모니터링 설정: 배포 후 Flask 애플리케이션, Hadoop, Spark 클러스터의 상태를 모니터링할 수 있는 시스템 설정(Grafana, Prometheus 등 활용 가능).
    3. **최종 발표 준비**:
        - 프로젝트 문서화: 프로젝트 구조, 사용된 기술, 배포 과정 등을 문서화.
        - 데모 준비: 프로젝트 발표 시연을 위한 최종 데모 준비. CI/CD 파이프라인을 활용한 자동화 시연 포함.
    4. **프로젝트 발표 및 피드백**:
        - 프로젝트 시연: CI/CD 파이프라인을 통해 배포된 영화 추천 서비스를 시연하고, 주요 기능과 성능 설명.
        - 피드백 수렴: 동료 및 멘토의 피드백을 받아 프로젝트 개선 사항 논의.
    5. **스터디 마무리**:
        - 전체 커리큘럼 복습: 프로젝트를 통해 배운 내용을 복습하고, 향후 학습 계획 논의.
        - 후속 작업 계획: 프로젝트의 추가 확장 가능성을 논의하고, 후속 프로젝트 또는 연구 계획 수립.

### **1차시: FastAPI 기초 및 환경 설정**

- **기술 스택**: Python, FastAPI, Uvicorn
- **학습 목표**:
    - **Python 및 FastAPI 설치**: 학습자는 Python 환경 설정 및 FastAPI 설치 과정을 학습하게 됩니다. VSCode 같은 개발 도구의 기본 설정도 함께 진행합니다.
    - **FastAPI의 기본 구조 이해**: FastAPI가 어떻게 요청을 처리하고, 경로(route)를 설정하는지, 그리고 요청 데이터를 처리하는 방법을 이해합니다.
    - **Uvicorn 서버 실행**: FastAPI 애플리케이션을 실행하기 위해 Uvicorn을 사용하고, 이를 통해 로컬 서버에서 API를 테스트하는 방법을 배웁니다.
- **실습 내용**:
    - **"Hello World" API 작성**: 간단한 FastAPI 프로젝트를 생성하여 "Hello World" 메시지를 반환하는 엔드포인트를 작성합니다.
    - **Path 및 Query Parameters 사용**: 경로 매개변수와 쿼리 매개변수를 사용하여 계산기 API를 만들어, 숫자 두 개를 받아 더하거나 빼는 기능을 구현합니다.
    - **Pydantic을 사용한 데이터 유효성 검사**: Pydantic 모델을 사용해 API 요청 데이터를 유효성 검사하고, 잘못된 입력에 대해 적절한 오류 메시지를 반환하는 방법을 학습합니다.

### **2차시: 영화 리뷰 감성 분석 모델 학습**

- **기술 스택**: Scikit-learn, Pandas, Joblib
- **학습 목표**:
    - **데이터셋 준비 및 전처리**: 영화 리뷰 데이터셋을 Pandas를 사용해 로드하고, 텍스트 전처리 과정을 거쳐 모델 학습에 적합한 형태로 변환하는 방법을 배웁니다.
    - **텍스트 벡터화**: Scikit-learn의 `CountVectorizer`를 사용해 텍스트 데이터를 벡터화하여 숫자 형태로 변환하는 방법을 학습합니다.
    - **모델 학습 및 평가**: Logistic Regression 모델을 학습시키고, 모델의 성능을 평가하는 방법을 학습합니다.
    - **모델 저장**: 학습된 모델을 Joblib을 사용해 파일로 저장하고, 이후 로딩하여 재사용하는 방법을 배웁니다.
- **실습 내용**:
    - **데이터셋 로딩**: Pandas를 사용해 CSV 파일로부터 영화 리뷰 데이터를 로드합니다.
    - **텍스트 전처리**: 텍스트 데이터를 소문자로 변환하고, 불필요한 문장 부호나 특수 문자를 제거하는 등의 전처리 과정을 수행합니다.
    - **모델 학습**: `CountVectorizer`를 사용해 텍스트 데이터를 벡터화하고, Logistic Regression 모델을 학습시킵니다.
    - **모델 저장 및 로딩**: 학습된 모델을 Joblib을 사용해 저장한 후, 저장된 모델을 다시 로딩해 성능을 테스트합니다.

### **3차시: FastAPI와 모델 통합**

- **기술 스택**: FastAPI, Scikit-learn, Joblib
- **학습 목표**:
    - **모델을 API에 통합**: Joblib으로 저장된 모델을 FastAPI 애플리케이션에 로드하여, API 엔드포인트에서 모델을 활용할 수 있도록 통합하는 방법을 학습합니다.
    - **의존성 주입**: FastAPI의 의존성 주입(Dependency Injection) 기능을 사용하여 모델을 여러 엔드포인트에서 재사용할 수 있도록 관리하는 방법을 배웁니다.
    - **POST 요청 처리**: 클라이언트로부터 POST 요청을 받아, 모델을 사용해 감성 분석을 수행하고 그 결과를 반환하는 엔드포인트를 구현합니다.
- **실습 내용**:
    - **모델 로딩**: FastAPI 애플리케이션에서 Joblib을 사용해 사전 학습된 모델을 로드합니다.
    - **의존성 주입**: FastAPI의 `Depends` 기능을 사용해 모델을 다른 엔드포인트에서 공유할 수 있도록 설정합니다.
    - **API 엔드포인트 작성**: POST 요청으로 영화 리뷰 텍스트를 받아 모델 예측값(긍정/부정)을 반환하는 엔드포인트를 작성합니다.

### **4차시: API 성능 최적화**

- **기술 스택**: FastAPI, Uvicorn, Background Tasks
- **학습 목표**:
    - **Uvicorn 성능 최적화**: Uvicorn 서버의 워커 수 조정과 같은 설정을 통해 FastAPI 애플리케이션의 성능을 최적화하는 방법을 학습합니다.
    - **비동기 작업 처리**: FastAPI의 Background Tasks를 사용해 비동기 작업을 처리하고, 모델 예측과 같은 시간이 오래 걸리는 작업을 효율적으로 관리하는 방법을 배웁니다.
    - **API 응답 시간 단축**: 비동기 작업과 Uvicorn 설정을 활용해 API 응답 시간을 단축시키는 방법을 학습합니다.
- **실습 내용**:
    - **Uvicorn 설정 최적화**: Uvicorn 서버의 `-workers` 옵션을 조정하여 멀티-스레드 환경에서 FastAPI 애플리케이션을 실행해봅니다.
    - **Background Tasks 구현**: 감성 분석 모델의 예측 작업을 비동기 처리하여, 클라이언트 요청에 대한 응답 시간을 줄이는 예제를 작성합니다.
    - **성능 테스트**: 최적화된 API의 성능을 로컬 환경에서 테스트하고, 개선된 응답 시간을 측정합니다.

### **5차시: Docker를 활용한 로컬 배포**

- **기술 스택**: Docker, Dockerfile, Docker Compose
- **학습 목표**:
    - **Docker 이해 및 활용**: Docker의 기본 개념을 이해하고, FastAPI 애플리케이션을 Docker 컨테이너로 패키징하는 방법을 학습합니다.
    - **Dockerfile 작성**: Dockerfile을 작성해 FastAPI 애플리케이션을 컨테이너 이미지로 빌드하는 방법을 배웁니다.
    - **Docker Compose 사용**: Docker Compose를 사용해 데이터베이스와 FastAPI 애플리케이션을 포함한 멀티 컨테이너 환경을 설정하고 관리하는 방법을 학습합니다.
- **실습 내용**:
    - **Dockerfile 작성**: FastAPI 애플리케이션을 패키징하기 위한 Dockerfile을 작성하고, 이를 통해 Docker 이미지를 빌드합니다.
    - **컨테이너 실행**: 빌드된 이미지를 사용해 Docker 컨테이너를 실행하고, 로컬 환경에서 FastAPI 애플리케이션을 실행합니다.
    - **Docker Compose 설정**: Docker Compose 파일을 작성해 FastAPI 애플리케이션과 데이터베이스를 함께 실행하고, 컨테이너 간의 네트워크 설정을 관리합니다.

### **6차시: MLflow를 활용한 모델 실험 관리 및 모니터링**

- **기술 스택**: MLflow, Scikit-learn, Pandas
- **학습 목표**:
    - **MLflow 기본 개념 이해**: MLflow의 기본 개념과 실험 관리 기능을 이해하고, 이를 통해 모델 학습과 관련된 실험을 추적하는 방법을 학습합니다.
    - **Experiment Tracking**: MLflow의 Experiment Tracking 기능을 활용해 모델 학습 과정에서 발생하는 메트릭, 파라미터, 모델 아티팩트를 기록하고 추적하는 방법을 배웁니다.
    - **Model Registry**: 학습된 모델을 MLflow Model Registry에 등록하고, 모델의 버전을 관리하는 방법을 학습합니다.
    - **로컬에서 MLflow 서버 실행**: MLflow 서버를 로컬에서 실행하고, 웹 UI를 통해 실험 기록과 모델을 관리하는 방법을 학습합니다.
- **실습 내용**:
    - **MLflow 설치 및 설정**: MLflow를 설치하고, 로컬에서 MLflow 서버를 실행해 웹 UI에 접근합니다.
    - **모델 학습 기록**: Scikit-learn을 사용해 모델을 학습시키면서 MLflow를 사용해 실험을 기록하고, 파라미터와 메트릭을 추적합니다.
    - **Model Registry 사용**: 학습된 모델을 MLflow Model Registry에 등록하고, 모델 버전을 관리합니다.
    - **실험 기록 분석**: MLflow UI를 사용해 기록된 실험 결과를 시각화하고, 실험 간의 비교를 통해 최적의 모델을 선택합니다.

### **7차시: API 테스트 및 문서화**

- **기술 스택**: FastAPI, Swagger, OpenAPI, Postman
- **학습 목표**:
    - **Swagger 및 OpenAPI 활용**: FastAPI의 내장 Swagger UI와 자동 생성되는 OpenAPI 문서를 활용해 API 문서화를 자동으로 생성하고 관리하는 방법을 학습합니다.
    - **Postman을 통한 API 테스트**: Postman을 사용해 작성한 API 엔드포인트를 테스트하고, API의 기능과 성능을 검증하는 방법을 배웁니다.
    - **자동화된 테스트 스크립트 작성**: 반복적인 API 테스트를 자동화하기 위해 Postman의 스크립트 기능을 사용해 테스트 자동화 방법을 학습합니다.
    - **프로젝트 문서화**: 프로젝트의 전체적인 사용법과 API 명세를 포함한 문서화를 작성하고, 이를 바탕으로 README 파일을 구성합니다.
- **실습 내용**:
    - **Swagger UI 활용**: FastAPI 애플리케이션을 실행하고, `/docs` 경로에서 자동 생성된 Swagger UI를 확인합니다.
    - **Postman을 사용한 테스트**: Postman을 사용해 API 엔드포인트를 호출하고, 요청과 응답을 확인하여 API의 기능을 검증합니다.
    - **테스트 스크립트 작성**: Postman에서 테스트 스크립트를 작성해 여러 요청을 자동으로 실행하고, 결과를 비교합니다.
    - **프로젝트 문서화 작성**: API의 사용법과 주요 기능을 설명하는 문서화 작업을 진행하고, README 파일로 구성합니다.

### **8차시: 프로젝트 유지보수 및 최종 검토**

- **기술 스택**: Git, MLflow, FastAPI
- **학습 목표**:
    - **Git을 활용한 버전 관리**: Git을 사용해 프로젝트 버전 관리와 협업을 효율적으로 수행하는 방법을 학습합니다.
    - **모델 성능 모니터링**: MLflow를 사용해 배포된 모델의 성능을 지속적으로 모니터링하고, 필요한 경우 모델을 재학습하고 업데이트하는 방법을 학습합니다.
    - **FastAPI 서버 유지보수**: FastAPI 서버에서 발생할 수 있는 문제들을 해결하고, 서버의 안정성을 유지하기 위한 최적화 방법을 학습합니다.

- **실습 내용**:
    - **Git을 사용한 코드 관리**: Git을 사용해 프로젝트를 버전 관리하고, 브랜치를 활용해 코드 변경 사항을 관리합니다.
    - **MLflow를 통한 모델 모니터링**: MLflow UI에서 모델의 실험 기록을 확인하고, 배포된 모델의 성능을 모니터링합니다. 필요한 경우 새로운 데이터로 모델을 재학습하고, 이를 다시 배포합니다.
    - **FastAPI 서버 문제 해결**: 서버에서 발생하는 문제를 디버깅하고, 성능 최적화 작업을 통해 서버의 안정성을 유지합니다.